{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transliteration_Minor1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOI4rlrgxPI-"
      },
      "source": [
        "## Outline\n",
        "\n",
        "\n",
        "1. Data set and task\n",
        "2. Data processing XML files\n",
        "3. encoder decoder architecture\n",
        "4. GRU based encoder decoder\n",
        "5. Adding attention\n",
        "6. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GqTjeV47m4B"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpuvHS0mxwCd"
      },
      "source": [
        "## Data Management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYrAa5laSptM"
      },
      "source": [
        "### Alphabets Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a04ZKx7Sh-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656fb997-e806-43bd-c61b-75e5e6c24cb7"
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPSZsy1kXd9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e731b1f8-07c2-483f-e987-0b9f2225e025"
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSw1SMZmx9A3"
      },
      "source": [
        "### Helper functions for data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcS6ByndOxrC"
      },
      "source": [
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ob3F9Dh4PChB"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGSeoMGg0FTy"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TransliterationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXmlDataset(filename, cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "    \n",
        "    def readXmlDataset(self, filename, lang_vocab_cleaner):\n",
        "        transliterationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in transliterationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            # Skip noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print('Skipping: ', line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index : end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size, self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size, self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size + 1\n",
        "        \n",
        "        # Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "            \n",
        "        return eng_batch, hindi_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FCCi-SerZS-"
      },
      "source": [
        "train_data = TransliterationDataLoader('train_transliteration.xml')\n",
        "test_data = TransliterationDataLoader('test_transliteration.xml')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7l-iaCVdx5Ez"
      },
      "source": [
        "### Basic Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjY06ghEx76b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc0fbe24-b48f-4bde-8e4f-50d83d3a7570"
      },
      "source": [
        "print(\"Train Set Size:\\t\", len(train_data))\n",
        "print(\"Test Set Size:\\t\", len(test_data))\n",
        "\n",
        "print('\\nSample data from train-set:')\n",
        "for i in range(10):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(eng + ' - ' + hindi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set Size:\t 20641\n",
            "Test Set Size:\t 1000\n",
            "\n",
            "Sample data from train-set:\n",
            "SALISH - सालिश\n",
            "KURDE - कुरडे\n",
            "HASEEN - हसीन\n",
            "INNISFALLEN - इनिसफॉलन\n",
            "MADAN - मदन\n",
            "FRANCISCO - फ्रान्सिस्को\n",
            "AZAMGARH - आजमगढ़\n",
            "MRAGANAYANEE - मृगनयनी\n",
            "WINONA - विनोना\n",
            "BANWET - बनवेट\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpDP1_KYZIkv"
      },
      "source": [
        "### Encoding the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE3at5C7Sy5F"
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word)+1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1, 1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yE3jToOrfzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66f6daa-f0f1-4e16-f796-760ef1a7d3bd"
      },
      "source": [
        "eng, hindi = train_data.get_random_sample()\n",
        "eng_rep = word_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_rep)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ROEBUCK tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMcDjIberhc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e555e9f4-2463-4b72-b5f8-331130467fee"
      },
      "source": [
        "hindi_gt = gt_rep(hindi, hindi_alpha2index)\n",
        "print(hindi, hindi_gt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "रोबक tensor([[49],\n",
            "        [76],\n",
            "        [45],\n",
            "        [22],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrC3tSnm4rUk"
      },
      "source": [
        "## Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4OgdZ_DVVC5"
      },
      "source": [
        "### Encoder-Decoder (using GRU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w8ffT3w4lkK"
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        out, hidden = self.encoder_rnn_cell(input)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder input', input.shape)\n",
        "            print('Encoder output', out.shape)\n",
        "            print('Encoder hidden', hidden.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        outputs = []\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder input', decoder_input.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "            \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "            one_hot.zero_()\n",
        "            one_hot.scatter_(2, max_idx, 1)\n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cra9toTiOoPm"
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyFcUMiuSbK4"
      },
      "source": [
        "def infer(net, word, char_limit, device = 'cpu'):\n",
        "\n",
        "    input = word_rep(word, eng_alpha2index, device)\n",
        "\n",
        "    return net(input, char_limit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4zaJq2pOrM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1f80559-1135-4dd6-a131-a503caa35929"
      },
      "source": [
        "out = infer(net, \"BAHADUR\", 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder input torch.Size([8, 1, 27])\n",
            "Encoder output torch.Size([8, 1, 256])\n",
            "Encoder hidden torch.Size([1, 1, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 129])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_pdzBmQOsjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "968feaf9-caea-48cd-b707-b828d1e0e661"
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ऎ\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ऎ\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ऎ\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ऎ\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ऎ\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ऎ\n",
            "torch.Size([1, 129]) श\n",
            "torch.Size([1, 129]) ॲ\n",
            "torch.Size([1, 129]) ऎ\n",
            "torch.Size([1, 129]) श\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEg49N9e7oTY"
      },
      "source": [
        "### Encoder-Decoder with Attention \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z-1QDAz8F_d"
      },
      "source": [
        "class Transliteration_EncoderDecoder_Attention(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose=False):\n",
        "        super(Transliteration_EncoderDecoder_Attention, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(hidden_size*2, hidden_size)\n",
        "        \n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "        \n",
        "        self.U = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.W = nn.Linear(self.hidden_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size, 1)\n",
        "        self.out2hidden = nn.Linear(self.output_size, self.hidden_size)   \n",
        "        \n",
        "        self.verbose = verbose\n",
        "        \n",
        "    def forward(self, input, max_output_chars = MAX_OUTPUT_CHARS, device = 'cpu', ground_truth = None):\n",
        "        \n",
        "        # encoder\n",
        "        encoder_outputs, hidden = self.encoder_rnn_cell(input)\n",
        "        encoder_outputs = encoder_outputs.view(-1, self.hidden_size)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Encoder output', encoder_outputs.shape)\n",
        "        \n",
        "        # decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        \n",
        "        outputs = []\n",
        "        U = self.U(encoder_outputs)\n",
        "        \n",
        "        if self.verbose:\n",
        "            print('Decoder state', decoder_state.shape)\n",
        "            print('Decoder intermediate input', decoder_input.shape)\n",
        "            print('U * Encoder output', U.shape)\n",
        "        \n",
        "        for i in range(max_output_chars):\n",
        "            \n",
        "            W = self.W(decoder_state.view(1, -1).repeat(encoder_outputs.shape[0], 1))\n",
        "            V = self.attn(torch.tanh(U + W))\n",
        "            attn_weights = F.softmax(V.view(1, -1), dim = 1) \n",
        "            \n",
        "            if self.verbose:\n",
        "                print('W * Decoder state', W.shape)\n",
        "                print('V', V.shape)\n",
        "                print('Attn', attn_weights.shape)\n",
        "            \n",
        "            attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "            \n",
        "            embedding = self.out2hidden(decoder_input)\n",
        "            decoder_input = torch.cat((embedding[0], attn_applied[0]), 1).unsqueeze(0)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Attn LC', attn_applied.shape)\n",
        "                print('Decoder input', decoder_input.shape)\n",
        "                \n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder intermediate output', out.shape)\n",
        "                \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "            \n",
        "            if self.verbose:\n",
        "                print('Decoder output', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim=True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1, 1, 1)\n",
        "            one_hot = torch.zeros(out.shape, device=device)\n",
        "            one_hot.scatter_(2, max_idx, 1) \n",
        "            \n",
        "            decoder_input = one_hot.detach()\n",
        "            \n",
        "        return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMD3zjdJO0Oj"
      },
      "source": [
        "net_attn = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoiQwbntO5UH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90d50f29-91a7-47be-a1f5-033ac8821d74"
      },
      "source": [
        "out = infer(net_attn, 'INDIA', 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output torch.Size([6, 256])\n",
            "Decoder state torch.Size([1, 1, 256])\n",
            "Decoder intermediate input torch.Size([1, 1, 129])\n",
            "U * Encoder output torch.Size([6, 256])\n",
            "W * Decoder state torch.Size([6, 256])\n",
            "V torch.Size([6, 1])\n",
            "Attn torch.Size([1, 6])\n",
            "Attn LC torch.Size([1, 1, 256])\n",
            "Decoder input torch.Size([1, 1, 512])\n",
            "Decoder intermediate output torch.Size([1, 1, 256])\n",
            "Decoder output torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9WSPgzlO6k8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "902e3681-3a3c-4cf0-c32d-e0ffc3440c75"
      },
      "source": [
        "print(len(out))\n",
        "for i in range(len(out)):\n",
        "    print(out[i].shape, list(hindi_alpha2index.keys())[list(hindi_alpha2index.values()).index(torch.argmax(out[i]))])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30\n",
            "torch.Size([1, 129]) क\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) झ\n",
            "torch.Size([1, 129]) क\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) झ\n",
            "torch.Size([1, 129]) क\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) झ\n",
            "torch.Size([1, 129]) क\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) झ\n",
            "torch.Size([1, 129]) क\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) झ\n",
            "torch.Size([1, 129]) क\n",
            "torch.Size([1, 129]) ॽ\n",
            "torch.Size([1, 129]) -PAD-\n",
            "torch.Size([1, 129]) झ\n",
            "torch.Size([1, 129]) क\n",
            "torch.Size([1, 129]) ॽ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyE2tSnmAW6x"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H893cimDtTUE"
      },
      "source": [
        "### Core Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m804jsH7AXSV"
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "    \n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
        "    \n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "        \n",
        "        input = word_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth = gt if teacher_force else None)\n",
        "        \n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion(output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "        \n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-eZaBxstWz9"
      },
      "source": [
        "### Training Helper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rjto129ssrpr"
      },
      "source": [
        "def train_setup(net, lr = 0.01, n_batches = 100, batch_size = 10, momentum = 0.9, display_freq=5, device = 'cpu'):\n",
        "    \n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(), lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "    \n",
        "    loss_arr = np.zeros(n_batches + 1)\n",
        "    \n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq-1:\n",
        "            clear_output(wait=True)\n",
        "            \n",
        "            print('Iteration', i, 'Loss', loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "            \n",
        "    torch.save(net, 'model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZY6RvqLtdX8"
      },
      "source": [
        "### Training without Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oQ3ZIWvtjfN"
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6LjVKQfoVMU"
      },
      "source": [
        "train_setup(net, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM1Tj20omMi1"
      },
      "source": [
        "### Training with Attention "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxFLBqW1Ip4v"
      },
      "source": [
        "net_att = Transliteration_EncoderDecoder_Attention(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdRpJUXNIwuv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "f6a6423a-adaa-44b5-caa7-a29c4c814322"
      },
      "source": [
        "loss_history = train_setup(net_att, lr=0.001, n_batches=2000, batch_size = 64, display_freq=10, device = device_gpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration 1999 Loss 0.14735378324985504\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05F1-FwX6YVZ"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3TWC7zhAn3z"
      },
      "source": [
        "def test(net, word, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    outputs = infer(net, word, 30, device)\n",
        "    hindi_output = ''\n",
        "    for out in outputs:\n",
        "        val, indices = out.topk(1)\n",
        "        index = indices.tolist()[0][0]\n",
        "        if index == 0:\n",
        "            break\n",
        "        hindi_char = hindi_alphabets[index+1]\n",
        "        hindi_output += hindi_char\n",
        "    print(word + ' - ' + hindi_output)\n",
        "    return hindi_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bT8bibYl7CgX"
      },
      "source": [
        "def calc_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions = []\n",
        "    accuracy = 0\n",
        "    for i in range(len(test_data)):\n",
        "        eng, hindi = test_data[i]\n",
        "        gt = gt_rep(hindi, hindi_alpha2index, device)\n",
        "        outputs = infer(net, eng, gt.shape[0], device)\n",
        "        correct = 0\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct/gt.shape[0]\n",
        "    accuracy /= len(test_data)\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy1bQiORAs5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c981272d-d162-4490-850f-edd96664434f"
      },
      "source": [
        "accuracy = calc_accuracy(net) * 100\n",
        "accuracy_attn = calc_accuracy(net_att) * 100\n",
        "print('Accuracy w/o attention ', accuracy)\n",
        "print('Acurracy with attention', accuracy_attn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy w/o attention  22.70685897435895\n",
            "Acurracy with attention 18.36795288045286\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}